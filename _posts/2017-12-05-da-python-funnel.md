---
title: "2회차: 유저 Funnel 분석을 통해 이탈 구간 개선"
layout: post
author: songhunhwa
---

### 목적
 - Funnel 분석의 개념을 이해하고 예시 데이터를 통해 분석 실습을 진행한다.
 - 마치 분석 프로젝트 업무를 맡은 PM이라 생각하고 2강 내용을 학습한다.

### 목차
 1. 배경, 문제 정의 및 가설 정립
 2. 분석 Frame 구성
 3. 데이터 전처리
 4. 데이터 분석 (EDA, Clustering 등)
 5. 시각화 및 리포트 작성

### 배경, 문제 정의 및 가설
여러분이 데이터 분석가로서 회사에 새로 입사했다고 가정해보자. 경력직으로서 여러분이 처음 맡은 업무는 기획팀에서 요청한 업무로, 기획부서에서 만든 새로운 시나리오 대로 유저가 앱을 잘 사용하고 있는지, 만약 그렇다면 어떤 기능이 잘 사용되고, 이탈이 많다면 어느 구간인지 어떻게 그 구간을 개선할지 알려달라는 요청을 받았다고 하자. 이러한 요청 내용을 바탕으로 요청 배경과 문제 정의는 다음과 같이 정리할 수 있다. 

#### 배경
문제의 배경은 보통 분석을 요청하는 외부의 팀(예, 기획, 마케팅 등)에 의해 발의되고, 여러 번의 논의를 통해 이루어진다. 논의가 마무리된 후 간단하게 배경과 목적 등을 정리하여 공유 및 최종 컨펌을 받아 놓는 것은 유용하다. 이번 가상 사례의 경우, 아래와 같이 배경이 정리될 수 있다.
 - 유저가 남긴 데이터를 기반으로 신규 시나리오/기능에 대한 사용성을 파악하고 개선점을 도출
 - 궁극적인 목적은 유저 피드백을 통한 Learning을 통해 전반적인 사용자 경험(UX)를 지속적으로 높이는 것

<img src="/img/lecture/ux_process.png" width="65%">

Source: [Impact Hub](https://bern.impacthub.net/event/lean-lab-learn-about-and-practice-value-proposition-design/)

#### 문제 정의(목적 설정)
문제를 정확하게 정의하고 목적을 설정하는 과정은 모든 분석 프로젝트 과정에서 가장 중요한 과정이라고 해도 과언이 아니다. 배경을 통해 문제를 정의하면 아래와 같이 정리할 수 있다. 만약 실무에서 모호한 부분이 있다면, 분석 요청자와 충분한 논의를 거쳐 이 단계를 보다 명확하게 진행하고 다음 단계로 넘어가는 것이 중요하다.
 - 신규 시나리오를 이해하고 분석적 관점과 요청 내용을 달성할 수 있는 관점을 기반으로 **적절한 데이터를 수집**
 - 수집된 데이터를 통해 유저의 행동 패턴을 파악함으로써, **선호 기능과 개선이 필요한 구간을 탐색** 
 - **Implications 도출**하여 실제적인 요청자의 행동 변화와 성과 개선에 기여
 
#### 가설 정립 및 예상 Ouput
가설을 설정하는 것은 도메인 지식이 충분하지 않거나 분석 업무 경험이 많지 않다면 어려울 수 있는 부분이다. 가설 설정은 상황에 따라 생략할 수 있는 부분이며, 오히려 데이터 탐색의 범위를 좁히는 결과를 낳기도 하기 때문에 목적 설정 과정에 비해 중요도가 높지 않다고 할 수 있다. 즉, 오픈 결론을 얻기 위해 가설 설정이 도움이 안 될 수 있다. 대신 가설을 만들고 예상 산출물(Ouput)을 그려보는 과정은 데이터 수집 및 분석 과정에서 수많은 의사결정을 진행할시 도움이 되기도 한다. 이번 가상 상황에서는 아래와 같이 가설을 미리 도출하여 예상 산출물을 어렴풋이 그려볼 수 있다.
 - 가설1: 이탈이 많이 발생하는 구간은 **구매 상세 페이지**에서 **구매 완료로 전환하는 구간**일 것이다.(Bottleneck)
 - 이유: 구매를 한다는 것은 돈을 지불해야 하는 행위이며 일반적으로 목적 달성이 어려움
 - 가설2: **그룹 조건에 따라 전환율이나 이탈율에서 통계적으로 유의미한 차이**를 보일 것이다.
 - 이유: 그룹 조건은 행동 패턴을 결정짓는 주요 요인중 하나이므로 위와 같은 결과가 나올 것. (단, 그룹 세분화가 진행되기 전이므로 다소 오픈 결론으로 유지)

 <img src="/img/lecture/output.png" width="70%">

### 분석 Frame 구성

#### MECE
분석 Frame을 최종 목표를 달성하기 위해, 그 최종 목표를 쪼개고 또 쪼개어 상세 목표를 만들어 가는 과정을 의미한다. 이 과정에 많이 쓰이는 철학과 방법론이 **MECE, Logic Tree**이다. MECE는 Mutually Exclusive Collectively Exhaustive의 약자로, 목적을 겹치지 않고 누락되지 않게 잘게 나눈 것이라고 할 수 있다. 이는 특히 특정 비즈니스 현상을 나타내는 지표를 계획할 때 유용하게 이용할 수 있다.    

<img src="/img/lecture/mece.png" width="30%">

Source: [Wikipedia](https://ko.wikipedia.org/wiki/MECE)

예를 들어, 특정 서비스의 건강도를 측정하는 지표를 계획한다고 가정해보자. 서비스 건강도를 일별 방문자수, 재방문율, 구매율 및 재구매율 등 서로 독립적인 하위 지표로 구성할 수 있으며(ME), 건강도를 나타내는 하위 지표를 누락없이 반영하여(CE) 건강도라는 최종적인 상태를 측정할 수 있을 것이다. 많은 논의를 통해 서로 독립적이며 누락없는 하위 지표를 구성한후 그 지표가 건강도를 잘 대표하고 있는지(타당도), 시간의 흐름에 관계 없이 Robust한 결과를 보이는지(신뢰도) 등 종합적으로 고려하여 지표를 설정하고 Tracking 하는 것은 분석 Frame 설정의 한 예시이다.
 
#### Logice Tree
이번엔 Logic Tree에 대해 알아보자. Logic Tree 모습은 마치 머신러닝 기법인 Decision Tree의 유사하다. 최종 목적을 세부적인 목적으로 분류하는 데 도움을 주는 방법론이다. 상위 단계에서 하위 단계로 구분되어 내려갈 때 MECE 철학에 근거해 잘게 쪼개질 때까지 진행하는 것이 중요하다.  

<img src="/img/lecture/logic_tree.png" width="70%">

Source: [DongaBiz](http://www.dongabiz.com)

#### 실습. UX 사용성 테스트에 맞는 Logic Tree 설계
지금까지 배운 MECE와 Logic Tree를 이용해, 유저 사용성 분석의 목적에 맞는 분석 Frame을 작성/실습해보자. 아래 예제를 참고하여 파워포인트나 키노트, 혹은 메모장 등 프로그램을 실행시켜 최종 목적부터 세부적인 목적까지 직접 작성해보고 Feedback을 구해보자. 반드시 박스와 선을 이용할 필요는 없다.

<img src="/img/lecture/ux_logic_tree.png" width="80%">

#### 추가 고려 요소
데이터가 입수되고 앞에서 살펴본 문제 정의, 가설 설정 및 분석 Frame 단계를 완료하였다면 분석 준비가 완료되었다고 볼 수 있다. 다만, 실무에서는 추가로 고려해야할 사항이 더 있다. 주로 Management와 관련된 부분으로, PM 확은 Team Manager, 분석 요청자와 아래와 같은 사항을 논의할 필요가 있다. 이미 언급한 대로, 분석 프로젝트는 분석가 혹은 분석팀 자체적으로 진행되는 경우가 없으므로 프로젝트를 둘러싼 외부적 상황에 따라 크게 영향 받기도 한다. 따라서 아래와 같은 고려 사항을 소홀히하지 않도록 해야 불필요한 리소스 낭비를 최소화할 수 있다.
 - **일정** (중간 단계별 공유, 최종 Ouput 발표, 공유 방식 등)
 - **Project/Task 우선순위** (동 기간 타 프로젝트가 있을 경우, 우선순위 조정)
 - **유관팀 사전 논의 및 데이터 엔지니어 지정** (Co-workers)
 - **필요 Resource** (소프트웨어, 서버 등)

### 데이터 전처리
목적을 정의했고 가설 정립 및 분석 Frame 단계를 마쳤다면, 실제 데이터를 수집/추출하여 분석 단계를 준비하는 **데이터 전처리** 단계를 진행한다. 수집/추출 단계는 데이터 엔지니어의 역할이 크고, 또 이 수업의 범위를 벗어난 내용이므로 생략한다. 단, 이러한 수집/추출 과정에서 무엇을 수집할지 그리고 데이터의 Quality를 파악하는 것은 분석가가 관여하는 부분임을 인지할 필요가 있다. 일반적으로 아래와 같은 이유로 바로 실제 분석을 하기 전, 데이터 전처리 단계를 반드시 거쳐야 한다.
 - 여러 개의 데이터 소스 활용: 테이블 스키마나 Label, Type 등이 상이하여, 통합을 위해 일관적인 방식으로 변환 필요
 - 데이터 기록/수집의 누락 및 오류 (Missing Value, Errors, typo 발생)
 - 자연스러운 혹은 기계적으로 발생하는 이상치 or 극단치
 - 분석 목적에 맞지 않은 변수 혹은 분포

위에 나열된 내용 이외에도 예상하지 못한 이유로 인해 결측치 및 이상치 등이 쉽게 발생할 수 있으며, 이러한 문제가 있는 데이터를 전처리하지 않고 분석 혹은 모델링 등의 업무를 진행할 경우 치명적인 문제/오류를 발생시킬 수 있으므로 매우 주의할 필요가 있다. 일반적으로 각 문제점별 데이터 전처리를 하는 방식은 아래와 같다. 
 - 데이터 Type, Label 등이 일관적이지 않은 경우: 프로그램에서 제공하는 함수를 통해 일괄적으로 변경 (예, SQL: Cast, Python: astype())
 - Missing Value
	- 수치형인 경우 Mean, Median 등 대푯값으로 채우거나 실수 예측 모델링 활용 (예, Linear Regression)
	- 카테고리형인 경우 Mode로 채우거나 분류 예측 모델링 활용 (예, Logistic Regression)
 - Errors, Typo 발생의 경우: 텍스트 처리 함수 활용 (예, Python: str.replace())
 - 이상치(outlier): IQR, Z-score, MAD 방식으로 이상치 제거
 - 불필요 변수가 많은 경우: PCA 등으로 차원 축소하거나 변수 중요도 파악후 불필요 변수 제거
 - 부적절한 분포의 변수 존재하는 경우: log, sqrt 등 함수로 분포 변환
 - 측정 단위(scale)이 차이가 클 경우: Scaling with StarndardScale or MinMaxScaler
